# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Bj52dZdlUvy3KFcvfN_9ojYJAjZAuq0C
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from datetime import datetime

# Step 1: Data Collection (Example dataset)
data = pd.read_csv('spotify.csv')

# Step 2: Feature Engineering
# One-hot encode 'song_id' feature
X = pd.get_dummies(data['song_id'], prefix='song')

# Extract relevant features from timestamp (e.g., hour of the day)
data['timestamp'] = pd.to_datetime(data['timestamp'], format="%d-%m-%YÂ %H:%M") # Convert timestamp to datetime object
X['hour_of_day'] = data['timestamp'].dt.hour
X['day_of_week'] = data['timestamp'].dt.dayofweek

y = data['repeated_play']

# Step 3: Model Training
# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train a RandomForestClassifier
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Step 4: Prediction
# Let's say we want to predict for a new user
# Here, we also need to one-hot encode the new user's song history
new_user_song_history = pd.DataFrame({'song_id': ['song1', 'song2', 'song3'],
                                      'timestamp': ['2024-04-27 10:00:00', '2024-04-25 15:30:00', '2024-04-20 08:45:00']})
new_user_encoded = pd.get_dummies(new_user_song_history['song_id'], prefix='song')

# Extract relevant features from new user's timestamp
new_user_song_history['timestamp'] = pd.to_datetime(new_user_song_history['timestamp'])  # Convert timestamp to datetime object
new_user_encoded['hour_of_day'] = new_user_song_history['timestamp'].dt.hour
new_user_encoded['day_of_week'] = new_user_song_history['timestamp'].dt.dayofweek

# Find the missing feature names
missing_features = set(X_train.columns) - set(new_user_encoded.columns)

# Add the missing features with zero values
for feature in missing_features:
    new_user_encoded[feature] = 0

# Check the updated feature names
print(new_user_encoded.columns)

# Predict the likelihood of repeated play

# Step 5: Evaluation (Optional)
# Evaluate the model performance (accuracy)
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print("Model Accuracy:", accuracy)

# Step 6: Deployment
# Deploy the trained model in the backend system to generate personalized recommendations for users
# Actual deployment involves integration with backend systems, databases, and APIs, which is beyond the scope of this example